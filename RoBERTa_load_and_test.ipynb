{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the latest Twitter RoBERTa sentiment model\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Define texts to analyze\n",
    "texts = [\n",
    "    \"I love this hackathon! It's amazing!\",\n",
    "    \"I'm feeling really down today...\",\n",
    "    \"This event is okay, not great but not bad either.\"\n",
    "]\n",
    "\n",
    "# Tokenize and classify each text\n",
    "for text in texts:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Get the predicted label\n",
    "    predicted_class = torch.argmax(outputs.logits, dim=-1).item()\n",
    "\n",
    "    # Get label mappings\n",
    "    label_mapping = model.config.id2label  # Maps LABEL_0, LABEL_1, LABEL_2 to real sentiments\n",
    "    sentiment = label_mapping[predicted_class]\n",
    "\n",
    "    print(f\"Text: {text} | Sentiment: {sentiment}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
